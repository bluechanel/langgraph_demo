from typing import Annotated
from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from pydantic import SecretStr
from langchain_tavily import TavilySearch
from langgraph.prebuilt import ToolNode, tools_condition
from pydantic import SecretStr
from dotenv import load_dotenv
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(verbose=True)

# æ­¤å¤„å®šä¹‰ä½ è‡ªå·±çš„æ¨¡å‹
llm = ChatOpenAI(model="qwen3_32")

# å®šä¹‰å·¥å…·
tool = TavilySearch(max_results=2)
tools = [tool]
# å·¥å…·ç»‘å®šåˆ°æ¨¡å‹
llm_with_tools = llm.bind_tools(tools)

# å®šä¹‰å›¾çŠ¶æ€
class State(TypedDict):
    messages: Annotated[list, add_messages]  # æ­¤å¤„ç»´æŠ¤å®Œæ•´çš„æ¶ˆæ¯å†å²

graph = StateGraph(State)

def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}
# ä½¿ç”¨LangGraphæä¾›çš„å·¥å…·èŠ‚ç‚¹
tool_node = ToolNode(tools=tools)

graph.add_node("chatbot", chatbot)
# æ·»åŠ å·¥å…·èŠ‚ç‚¹
graph.add_node("tools", tool_node)
# æ·»åŠ å·¥å…· æ¡ä»¶åˆ†æ”¯
graph.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph.add_edge("tools", "chatbot")
graph.add_edge(START, "chatbot")

app = graph.compile()

if __name__ == "__main__":
    messages = []
    while True:
        user_input = input("ğŸ‘¨â€ğŸ’»: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Exiting...")
            break
        messages.append({"role": "user", "content": user_input})
        response = app.invoke({"messages": messages})
        messages = response["messages"]
        print(f'ğŸ¤–: {response["messages"][-1].content}')