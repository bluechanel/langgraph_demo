import json
from langchain_core.messages import ToolMessage
from langgraph.constants import END
from typing import Annotated, Type, Optional
from langchain_core.callbacks import CallbackManagerForToolRun, AsyncCallbackManagerForToolRun

from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from pydantic import SecretStr, BaseModel, Field
from langchain_core.tools import BaseTool
from tavily import TavilyClient, AsyncTavilyClient
from dotenv import load_dotenv
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(verbose=True)

# è‡ªå®šä¹‰å·¥å…·éƒ¨åˆ†
class TavilySearchInput(BaseModel):
    query: str = Field(description=("æœç´¢æŸ¥è¯¢"))

class TavilySearchTool(BaseTool):
    name: str = "tavily_search"
    description: str = """ä¸€ä¸ªé’ˆå¯¹å…¨é¢ã€å‡†ç¡®å’Œå¯ä¿¡çš„ç»“æœè¿›è¡Œäº†ä¼˜åŒ–çš„æœç´¢å¼•æ“ã€‚
å½“éœ€è¦å›ç­”æœ‰å…³æ—¶äº‹çš„é—®é¢˜æ—¶å¾ˆæœ‰ç”¨ã€‚
è¾“å…¥åº”è¯¥æ˜¯æœç´¢æŸ¥è¯¢ã€‚"""
    args_schema: Type[BaseModel] = TavilySearchInput
    # return_direct: bool = True

    def _run(
        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> int:
        client = TavilyClient()
        search_r = client.search(query=query, max_results=2)
        return search_r

    async def _arun(
        self,
        query: str,
        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
    ) -> int:
        client = AsyncTavilyClient()
        search_r = await client.search(query=query, max_results=2)
        return search_r

# è‡ªå®šä¹‰çš„å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹
class ToolNode:
    def __init__(self, tools: list) -> None:
        self.tools_by_name = {tool.name: tool for tool in tools}

    def __call__(self, inputs: dict):
        if messages := inputs.get("messages", []):
            message = messages[-1]
        else:
            raise ValueError("No message found in input")
        outputs = []
        for tool_call in message.tool_calls:
            print(f'æ­£åœ¨æ‰§è¡Œå·¥å…· {tool_call["name"]}ï¼Œå‚æ•° {tool_call["args"]}')
            tool_result = self.tools_by_name[tool_call["name"]].invoke(
                tool_call["args"]
            )
            print(f'å·¥å…·{tool_call["name"]}, æ‰§è¡Œç»“æœ{json.dumps(tool_result, ensure_ascii=False)}')
            outputs.append(
                ToolMessage(
                    content=json.dumps(tool_result, ensure_ascii=False),
                    name=tool_call["name"],
                    tool_call_id=tool_call["id"],
                )
            )
        return {"messages": outputs}

# æ­¤å¤„å®šä¹‰ä½ è‡ªå·±çš„æ¨¡å‹
llm = ChatOpenAI(model="qwen3_32")
# å®šä¹‰å·¥å…·
tool = TavilySearchTool()
tools = [tool]
# å·¥å…·ç»‘å®šåˆ°æ¨¡å‹
llm_with_tools = llm.bind_tools(tools)
# å®šä¹‰å›¾çŠ¶æ€
class State(TypedDict):
    messages: Annotated[list, add_messages]  # æ­¤å¤„ç»´æŠ¤å®Œæ•´çš„æ¶ˆæ¯å†å²
graph = StateGraph(State)
def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

# å·¥å…·è·¯ç”±
def route_tools(state: State):
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"No messages found in input state to tool_edge: {state}")
    if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
        return "tools"
    return END

# ä½¿ç”¨LangGraphæä¾›çš„å·¥å…·èŠ‚ç‚¹
tool_node = ToolNode(tools=tools)
graph.add_node("chatbot", chatbot)
# æ·»åŠ å·¥å…·èŠ‚ç‚¹
graph.add_node("tools", tool_node)
# æ·»åŠ å·¥å…·æ¡ä»¶è¾¹
graph.add_conditional_edges(
    "chatbot",
    route_tools,
    {"tools": "tools", END: END},
)
graph.add_edge("tools", "chatbot")
graph.add_edge(START, "chatbot")
app = graph.compile()

if __name__ == "__main__":
    messages = []
    while True:
        user_input = input("ğŸ‘¨â€ğŸ’»: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Exiting...")
            break
        messages.append({"role": "user", "content": user_input})
        response = app.invoke({"messages": messages})
        messages = response["messages"]
        print(f'ğŸ¤–: {response["messages"][-1].content}')