from dotenv import load_dotenv
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(verbose=True)
from typing import Annotated
from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START
from langgraph.constants import END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import InMemorySaver

llm = ChatOpenAI(model="qwen3_32")
memory = InMemorySaver()
# çœç•¥é‡å¤ä»£ç 
class ChildState(TypedDict):
    messages: Annotated[list, add_messages]
    preference: str

# å­å›¾ï¼Œä½¿ç”¨å­å›¾è‡ªå®šä¹‰çš„çŠ¶æ€
child_graph = StateGraph(ChildState)
def summarize_memory(state: ChildState):
    """æ€»ç»“è¿‡å¾€çš„å†å²èŠå¤©"""
    summary_prompt = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªæ€»ç»“åŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ˜æ‰¼è¦çš„è¯­è¨€æ€»ç»“å¯¹è¯å†å²ã€‚",
        },
        {"role": "user", "content": str(state["messages"])},
    ]
    result = llm.invoke(summary_prompt)
    return {"preference": result.content}
child_graph.add_node("summarize", summarize_memory)
child_graph.add_edge("summarize", END)
child_graph.add_edge(START, "summarize")
child_graph_compile = child_graph.compile()


class State(TypedDict):
    messages: Annotated[list, add_messages]  # æ­¤å¤„ç»´æŠ¤å®Œæ•´çš„æ¶ˆæ¯å†å²
    mem0_user_id: str
    preference: str
# çˆ¶å›¾
parent_graph = StateGraph(State)
def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}

# ç¼–å†™å­å›¾è°ƒç”¨å‡½æ•°
def call_subgraph(state: State):
    response = child_graph_compile.invoke({"messages": state["messages"]})
    return {"preference": response["preference"]}

parent_graph.add_node("chatbot", chatbot)
# æ·»åŠ å­å›¾èŠ‚ç‚¹
parent_graph.add_node("child_graph", call_subgraph)
parent_graph.add_edge("chatbot", "child_graph")
parent_graph.add_edge("child_graph", END)
parent_graph.add_edge(START, "chatbot")
app = parent_graph.compile(checkpointer=memory)

if __name__ == "__main__":
    while True:
        user_input = input("ğŸ‘¨â€ğŸ’»: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Exiting...")
            break
        response = app.invoke(
            {"messages": {"role": "user", "content": user_input}},
            config={"configurable": {"thread_id": "1"}},
        )
        messages = response["messages"]
        print(f'ğŸ¤–: {response["messages"][-1].content}')
        print("--" * 10)
        print(f'ğŸ”…å†å²èŠå¤©è®°å½•æ€»ç»“: {response["preference"]}')